# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ToTUR6FQ5aWN6kkpq8fEHjqyqb8HHth4
"""

import asyncio
import aiohttp
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# -----------------------
# async fetch NASA POWER data
# -----------------------
async def fetch_power(session, lat, lon, start, end, params):
    url = (
        "https://power.larc.nasa.gov/api/temporal/hourly/point"
        f"?start={start}&end={end}&latitude={lat}&longitude={lon}"
        f"&parameters={','.join(params)}&format=JSON&community=RE"
    )
    async with session.get(url) as resp:
        resp.raise_for_status()
        js = await resp.json()
        return js["properties"]["parameter"]

async def get_raw_data_async(target_dt, lat, lon, params, window=5, years_back=10):
    dfs = []
    async with aiohttp.ClientSession() as session:
        tasks = []
        for y in range(1, years_back+1):
            past_year = target_dt.year - y
            start = (target_dt.replace(year=past_year) - timedelta(days=window)).strftime("%Y%m%d")
            end   = (target_dt.replace(year=past_year) + timedelta(days=window)).strftime("%Y%m%d")
            tasks.append(fetch_power(session, lat, lon, start, end, params))
        results = await asyncio.gather(*tasks)

    # convert to dataframe list
    for i, r in enumerate(results, 1):
        past_year = target_dt.year - i
        df = pd.DataFrame({p: pd.Series(r[p]) for p in params})
        df.index = pd.to_datetime(df.index, format="%Y%m%d%H")
        df["year"] = past_year
        df["hour"] = df.index.hour
        dfs.append(df)

    full_df = pd.concat(dfs, axis=0)
    return full_df.reset_index(drop=True)

# -----------------------
# Create hourly–yearly averages
# -----------------------
def make_hourly_yearly_avg_df(raw_df, params):
    avg_df = raw_df.groupby(["year", "hour"])[params].mean().reset_index()
    return avg_df

# -----------------------
# Example usage
# -----------------------
params = ["T2M","RH2M","PRECTOTCORR","ALLSKY_SFC_SW_DWN","WS2M", "PS"]
target_dt = datetime(2025,10,4,12)

# In Colab, use await directly instead of asyncio.run() because an event loop is already running.
raw_df = asyncio.run(get_raw_data_async(target_dt, 10.823, 106.63, params))
print("Raw data (head):")
print(raw_df.head())

avg_df = make_hourly_yearly_avg_df(raw_df, params)
print("\nYearly-hourly average (head):")
print(avg_df.head())
print(avg_df.tail())

import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.multioutput import MultiOutputRegressor

def forecast_lightgbm_multitarget(raw_df, params, target_dt):
    """
    Dự đoán nhiều tham số khí tượng đồng thời (multi-target) cho 24h ngày target.
    """
    df = raw_df.copy()

    # Encode chu kỳ giờ
    df["sin_hour"] = np.sin(2*np.pi*df["hour"]/24)
    df["cos_hour"] = np.cos(2*np.pi*df["hour"]/24)

    # Features
    X = df[["hour", "sin_hour", "cos_hour", "year"]]
    y = df[params]

    # Train-test split
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)

    # Multi-output LightGBM
    model = MultiOutputRegressor(
        lgb.LGBMRegressor(objective="regression", n_estimators=200, learning_rate=0.05, random_state=42)
    )
    model.fit(X_train, y_train)

    # Prepare target day
    hours = range(24)
    X_pred = pd.DataFrame({
        "hour": hours,
        "sin_hour": np.sin(2*np.pi*np.array(hours)/24),
        "cos_hour": np.cos(2*np.pi*np.array(hours)/24),
        "year": target_dt.year
    })

    y_pred = model.predict(X_pred)
    pred_df = pd.DataFrame(y_pred, columns=params)
    pred_df["datetime"] = [target_dt.replace(hour=h, minute=0, second=0, microsecond=0) for h in hours]

    # reorder columns
    pred_df = pred_df[["datetime"] + params]
    return pred_df

params = ["T2M","RH2M","PRECTOTCORR","ALLSKY_SFC_SW_DWN","WS2M","PS"]
pred_df = forecast_lightgbm_multitarget(raw_df, params, target_dt)
print(pred_df.head())

def compute_ci_multitarget(raw_df, params, target_dt, ci_levels=[0.3,0.6,0.9]):
    """
    Tạo dataframe dự đoán + các khoảng tin cậy từ dữ liệu quá khứ.
    """
    hours = range(24)
    pred_dt_index = [target_dt.replace(hour=h, minute=0, second=0, microsecond=0) for h in hours]
    ci_dict = {"datetime": pred_dt_index}

    for p in params:
        for h in hours:
            # lấy giá trị của giờ h qua các năm
            values = raw_df[raw_df["hour"]==h][p].dropna()
            if len(values)==0:
                values = pd.Series([0])
            for ci in ci_levels:
                lower = np.percentile(values, 50 - ci*50)
                upper = np.percentile(values, 50 + ci*50)
                ci_dict.setdefault(f"{p}_low_{int(ci*100)}", []).append(lower)
                ci_dict.setdefault(f"{p}_high_{int(ci*100)}", []).append(upper)
        # mean trung bình
        mean_vals = [raw_df[raw_df["hour"]==h][p].mean() for h in hours]
        ci_dict[p] = mean_vals

    return pd.DataFrame(ci_dict)

import matplotlib.pyplot as plt

def plot_fanmap(pred_df, param, ci_levels=[30,60,90]):
    plt.figure(figsize=(12,5))
    x = pred_df["datetime"]

    # vẽ các khoảng tin cậy
    for ci in sorted(ci_levels, reverse=True):
        plt.fill_between(
            x,
            pred_df[f"{param}_low_{ci}"],
            pred_df[f"{param}_high_{ci}"],
            alpha=0.3*(ci/90),  # càng lớn alpha càng mờ
            label=f"{ci}% CI"
        )

    # vẽ đường trung bình
    plt.plot(x, pred_df[param], color='black', linewidth=2, label="Mean")

    plt.xlabel("Hour")
    plt.ylabel(param)
    plt.title(f"Fan Map for {param} on {x[0].date()}")
    plt.legend()
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.show()

params = ["T2M","RH2M","PRECTOTCORR","ALLSKY_SFC_SW_DWN","WS2M"]
ci_levels = [0.3, 0.6, 0.9]

ci_df = compute_ci_multitarget(raw_df, params, target_dt, ci_levels)
print(ci_df.head())

# vẽ fan map cho T2M
plot_fanmap(ci_df, "T2M", ci_levels=[30,60,90])
plot_fanmap(ci_df, "RH2M", ci_levels=[30,60,90])
plot_fanmap(ci_df, "PRECTOTCORR", ci_levels=[30,60,90])
plot_fanmap(ci_df, "ALLSKY_SFC_SW_DWN", ci_levels=[30,60,90])
plot_fanmap(ci_df, "WS2M", ci_levels=[30,60,90])

def extreme_prob_day_quantile(raw_df, target_dt):
    """
    Tính xác suất các hiện tượng cực đoan trong ngày target
    dựa trên 10% – 90% quantile của dữ liệu lịch sử.
    """
    # Chọn các tham số quan tâm
    params = ["T2M","PRECTOTCORR","ALLSKY_SFC_SW_DWN","WS2M","RH2M"]
    result = {}

    for p in params:
        hist = raw_df[p].values
        low_thresh = np.percentile(hist, 10)
        high_thresh = np.percentile(hist, 90)
        prob_low = (hist < low_thresh).mean() * 100
        prob_high = (hist > high_thresh).mean() * 100

        # Gán tên hiện tượng
        if p == "T2M":
            result[f"Nhiệt độ thấp"] = (prob_low, low_thresh)
            result[f"Nhiệt độ cao"] = (prob_high, high_thresh)
        elif p == "PRECTOTCORR":
            result[f"Mưa to"] = (prob_high, high_thresh)
        elif p == "ALLSKY_SFC_SW_DWN":
            result[f"Nắng yếu"] = (prob_low, low_thresh)
            result[f"Nắng gắt"] = (prob_high, high_thresh)
        elif p == "WS2M":
            result[f"Gió lớn"] = (prob_high, high_thresh)
        elif p == "RH2M":
            result[f"Độ ẩm thấp"] = (prob_low, low_thresh)
            result[f"Độ ẩm cao"] = (prob_high, high_thresh)

    return result

"""Dự đoán xác suất xảy ra thời tiết cực đoan"""

import numpy as np

# Công thức tính Heat Index (Steadman's formula, simplified, T: °C, RH: %)
def compute_heat_index(T, RH):
    # Convert T to Fahrenheit
    T_F = T * 9/5 + 32
    HI_F = (
        -42.379 + 2.04901523*T_F + 10.14333127*RH
        - 0.22475541*T_F*RH - 6.83783e-3*T_F**2
        - 5.481717e-2*RH**2 + 1.22874e-3*T_F**2*RH
        + 8.5282e-4*T_F*RH**2 - 1.99e-6*T_F**2*RH**2
    )
    # convert back to Celsius
    HI_C = (HI_F - 32) * 5/9
    return HI_C

def classify_extremes(df):
    df = df.copy()
    df["heat_index"] = compute_heat_index(df["T2M"], df["RH2M"])

    df["very_hot"]  = df["T2M"] >= 35
    df["very_cold"] = df["T2M"] <= 10
    df["very_wet"]  = df["PRECTOTCORR"] >= 5   # ~50 mm/day equivalent
    df["very_windy"]= df["WS2M"] >= 17
    df["uncomfortable"] = df["heat_index"] >= 41
    return df

def calc_probabilities(raw_df):
    df = classify_extremes(raw_df)

    probs = {}
    total = len(df)
    for col in ["very_hot","very_cold","very_wet","very_windy","uncomfortable"]:
        probs[col] = df[col].sum() / total * 100  # %
    return probs

# -----------------------
# Example usage
# -----------------------
probs = calc_probabilities(raw_df)
print("Probabilities of extreme conditions (%):")
for k,v in probs.items():
    print(f"{k}: {v:.2f}%")

"""### Khuyến nghị về sức khỏe"""

def classify_level(score):
    if score < 20:
        return "Low"
    elif score < 40:
        return "Moderate"
    elif score < 60:
        return "High"
    elif score < 80:
        return "Very High"
    else:
        return "Extreme"

def health_risk_prediction(df):
    results = []
    for _, row in df.iterrows():
        risks = {}
        T = row["T2M"]          # Temp (°C)
        H = row["RH2M"]         # Humidity (%)
        P = row["PS"] * 10      # Surface Pressure (convert kPa → hPa)
        W = row["WS2M"]         # Wind speed (m/s)
        S = row["ALLSKY_SFC_SW_DWN"]  # Solar radiation (W/m²)

        # Arthritis
        arthritis_score = max(0, (20 - T) * 2) + max(0, H - 70) * 0.5 + abs(P - 1013) * 0.1
        risks["Arthritis"] = classify_level(min(100, arthritis_score))

        # Sinus Pressure
        sinus_score = max(0, H - 60) * 0.7 + abs(P - 1013) * 0.3
        risks["Sinus Pressure"] = classify_level(min(100, sinus_score))

        # Common Cold
        cold_score = max(0, (18 - T) * 2) + max(0, 40 - H)
        risks["Common Cold"] = classify_level(min(100, cold_score))

        # Flu
        flu_score = max(0, (15 - T) * 3) + max(0, 50 - H)
        risks["Flu"] = classify_level(min(100, flu_score))

        # Migraine
        migraine_score = max(0, (T - 30) * 2) + max(0, S - 500) * 0.05 + abs(P - 1013) * 0.3
        risks["Migraine"] = classify_level(min(100, migraine_score))

        # Asthma
        asthma_score = max(0, H - 75) + max(0, W - 5) * 5 + max(0, S - 600) * 0.05
        risks["Asthma"] = classify_level(min(100, asthma_score))

        results.append({
            "datetime": row["datetime"],
            **risks
        })
    return pd.DataFrame(results)

# -----------------------
# Example usage
# -----------------------
# Use existing raw_df and pred_df_lgbm
health_pred_df = health_risk_prediction(pred_df) # Use lgbm prediction for health risk
print("\nHealth risk prediction (head):")
print(health_pred_df.head())

# Tính các phân vị
ci_levels = [0.3, 0.6, 0.9]
ci_df = compute_ci_multitarget(raw_df, params, target_dt, ci_levels)

# Gộp vào dự báo từng giờ
pred_full_df = pd.merge(pred_df, ci_df, on="datetime", how="left")

# Lưu dự báo thời tiết kèm phân vị
pred_full_df.to_json("weather_prediction.json", orient="records", date_format="iso")

# Lưu dự báo sức khỏe
health_pred_df.to_json("health_advice.json", orient="records", date_format="iso")